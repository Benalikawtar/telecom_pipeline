# ğŸ“¡ Telecom Data Pipeline â€“ Big Data Project

Ce projet simule le traitement des donnÃ©es techniques dâ€™un opÃ©rateur tÃ©lÃ©com (CDR/EDR) Ã  travers un pipeline complet, en utilisant les technologies Big Data modernes.

## ğŸ¯ Objectif

Construire un pipeline capable de gÃ©rer la gÃ©nÃ©ration, la mÃ©diation, la tarification et la facturation des enregistrements dâ€™usage (voix, SMS, data), en temps rÃ©el ou en batch.

## ğŸ”§ Ã‰tapes du pipeline

### 1. ğŸ” GÃ©nÃ©ration des donnÃ©es
- GÃ©nÃ©ration de CDR/EDR rÃ©alistes (voix, SMS, data)
- Distribution configurable (ex. 60 % voix, 30 % data, 10 % SMS)
- Injection dâ€™anomalies : champs manquants, corrompus, doublons, timestamps dÃ©sordonnÃ©s
- Sortie vers fichier JSON ou Kafka (`telecom_cdr_topic`)

### 2. âš™ï¸ MÃ©diation en streaming (Spark Streaming)
- Lecture depuis Kafka
- Parsing des enregistrements JSON
- Extraction du `msisdn` depuis `caller_id`, `sender_id` ou `user_id`
- VÃ©rification dâ€™erreurs et statuts (`normal`, `error`)
- Suppression des doublons
- SÃ©paration : envoi vers `clean_cdr_topic` ou `error_cdr_topic`

### 3. ğŸ’° Moteur de tarification (Batch)
- Lecture des donnÃ©es propres depuis Kafka
- Jointure avec les tables PostgreSQL : `customers`, `products`, `rate_plans`, `product_rates`
- Application des rÃ¨gles tarifaires selon le type de service, la zone, les promotions, le statut client
- Calcul du coÃ»t, gestion des statuts (`rated`, `rejected`, `unmatched`, `error`)
- Insertion dans la table `usage_records`

### 4. ğŸ§¾ Moteur de facturation (Batch)
- AgrÃ©gation mensuelle des coÃ»ts par client
- Application des taxes, quotas, remises
- GÃ©nÃ©ration de factures (format JSON)
- Sauvegarde dans la table `bills` (ou export)

## ğŸ› ï¸ Stack technique

- **Python** â€“ traitement et scripts
- **Apache Spark 3.4.2** â€“ streaming et batch
- **Apache Kafka** â€“ ingestion en temps rÃ©el
- **PostgreSQL** â€“ stockage des mÃ©tadonnÃ©es et rÃ©sultats
- **Docker / WSL Ubuntu** â€“ environnement dâ€™exÃ©cution

## ğŸ—ƒï¸ Structure du projet

Le projet est organisÃ© de maniÃ¨re modulaire pour sÃ©parer les diffÃ©rentes Ã©tapes du pipeline :

- `generate_cdr.py` : GÃ©nÃ©ration de fichiers CDR/EDR rÃ©alistes avec anomalies
- `producer.py` : Envoi des donnÃ©es vers Kafka (topic `telecom_cdr_topic`)
- `stream_mediation.py` : MÃ©diation en streaming avec Spark, sÃ©paration clean/error
- `rating_engine.py` : Moteur de tarification batch avec PostgreSQL
- `billing_engine.py` : AgrÃ©gation des coÃ»ts et gÃ©nÃ©ration des factures
- `docker-compose.yml` : Configuration des services Kafka, Spark, PostgreSQL
- `telecom_records.json` : Fichier dâ€™exemple des CDR simulÃ©s
- `checkpoints/` : RÃ©pertoires de sauvegarde Spark pour tolÃ©rance aux pannes
- `lib/` : Fichiers JAR nÃ©cessaires Ã  la connexion PostgreSQL


